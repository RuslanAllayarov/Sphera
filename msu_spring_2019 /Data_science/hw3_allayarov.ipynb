{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 30 апреля 2018, 06:00   \n",
    "**Штраф за опоздание:** -2 балла после 06:00 30 апреля, -4 балла после 06:00 7 мая, -6 баллов после 06:00 14 мая, -8 баллов после 06:00 21 мая\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    " \n",
    "    def __init__(self, min_samples_split=2, min_samples_leaf=1, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    " \n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    " \n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return 1 - ((np.sum(np.hstack((l_c * l_c / l_s, r_c * r_c / r_s)),\n",
    "                            axis=1)) / (l_s[0] + r_s[0]))\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return -np.sum(np.hstack((l_c * np.log2(l_c / l_s),\n",
    "                                  r_c * np.log2(r_c / r_s)),\n",
    "                                 axis=1))/(l_s[0] + r_s[0])\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return 1 - (np.max(l_c, axis=1) + np.max(r_c, axis=1)) / (l_s + r_s)\n",
    "    \n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = list(range(n_feature))\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.sqrt(n_feature))]\n",
    " \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = list(range(n_feature))\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.log2(n_feature))]\n",
    " \n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    " \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "    \n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # сортировка x и y\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        # class_number - количество уникальных классов в y\n",
    "        class_number = self.num_class\n",
    " \n",
    "        # cut_size - у нас точно граница пройдет не через них\n",
    "        cut_size = round(self.min_samples_split / 2) - 1\n",
    "        # делим наши y \n",
    "        if (cut_size != 0):\n",
    "            splitted_sorted_y = sorted_y[cut_size:-cut_size]\n",
    "        else:\n",
    "            splitted_sorted_y = sorted_y\n",
    "        # здесь находим индексы элементов, у которых сосед совпадает с ними\n",
    "        # то есть находим правых соседей пар одинаковых элементов\n",
    "        # сохраняем в r_border_ids\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (cut_size + 1)\n",
    "        \n",
    "        # если класс не менялся вообще, выходим из threshold\n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None\n",
    " \n",
    "        # Получаем количество одинаковых идущих подряд элементов в интервале.\n",
    "        # Потом создаем матрицу, с единицами на местах где происходит смена.\n",
    "        eq_el_count = r_border_ids - np.append([cut_size], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        # Затем делаем матрицу количества классов для каждого интервала.\n",
    "        # Для 0 позиции добавляем число вырезанных элементов. \n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:cut_size], minlength=class_number)\n",
    " \n",
    "        # В i строке l_class_count будут лежать количества\n",
    "        # элементов каждого класса встретившихся до r_border_ids[i]-го момента\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)\n",
    "        r_class_count = np.bincount(sorted_y, minlength=class_number) - l_class_count\n",
    "        # Размеры разбиений\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    " \n",
    "        # Считаем Gain, берем наименьший\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    " \n",
    "        # left_el_id - индекс наилучшего разбиения\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        # Возвращает эту меру неопределенности и элемент и значение, для разбиения выборки\n",
    "        return gs[idx], (sorted_x[left_el_id - 1] + sorted_x[left_el_id]) / 2.0\n",
    " \n",
    " \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, ind=-1):\n",
    "        # ind = -1 чтобы отследить факт захода первый\n",
    "        # ввел так как нельзя менять fit\n",
    "        if (ind == -1):\n",
    "            self.feature_importances_ = np.zeros(x.shape[1])\n",
    "            self.Size_ = x.shape[1]    \n",
    "        # p - вероятности\n",
    "        p = np.bincount(y, minlength=self.num_class) / x.shape[0]\n",
    "        moda = np.argmax(p)\n",
    "        # Критерии останова\n",
    "        if self.max_depth is not None and depth >= self.max_depth or\\\n",
    "                    y.shape[0] < self.min_samples_split or\\\n",
    "                    self.sufficient_share <= p[moda]:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, moda, p)\n",
    "            return \n",
    "\n",
    "        ids = self.get_feature_ids(x.shape[1])\n",
    "        thresholds = np.array([self.__find_threshold(x[:, idx], y) for idx in ids])\n",
    "        # best - наилучший признак, по какому бить надо\n",
    "        best = thresholds[:, 0].argmin()\n",
    "        thr = thresholds[best, 1]\n",
    "        # imp_curr - новая неопределенность, самая наименьшая по фичам\n",
    "        imp_curr = thresholds[best, 0]\n",
    "\n",
    "        if (thr is None):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, moda, p)\n",
    "            return\n",
    "\n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, ids[best], thr)\n",
    "        if (x_l.shape[0] == 0 or x_r.shape[0] == 0):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, moda, p)\n",
    "            return\n",
    "\n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, ids[best], thr)\n",
    "\n",
    "        # считаем feature_importance\n",
    "        # imp_prev - значение прошлой неопределенности в узле\n",
    "        if self.G_function == self.__gini:\n",
    "            imp_prev = 1 - np.sum(p ** 2)\n",
    "        elif self.G_function == self.__entropy:\n",
    "            imp_prev = -np.sum(p * np.log2(p))\n",
    "        else:\n",
    "            imp_prev = 1 - np.max(p)\n",
    "        # print('imp_prev = ', imp_prev, ' '*5, 'imp_curr = ', imp_curr)\n",
    "        self.feature_importances_[ids[best]] += x.shape[0] * (imp_prev - imp_curr) / self.Size_\n",
    "        \n",
    "        self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1, 0)\n",
    "        self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1, 0)\n",
    "\n",
    "        \n",
    "        \n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    " \n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    " \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    " \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    " \n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 ms, sys: 0 ns, total: 2.62 ms\n",
      "Wall time: 1.78 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 ms, sys: 53 µs, total: 25.1 ms\n",
      "Wall time: 24.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MyDecisionTreeClassifier at 0x7fd3fc058550>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9474747474747475"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9474747474747475"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('speed-dating-experiment/Speed Dating Data.csv', encoding='cp1251', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, :97]\n",
    "df = df.drop(['id', 'idg', 'condtn', 'round', 'position', 'positin1',\n",
    "             'order', 'partner', 'age_o', 'race_o', 'pf_o_att', 'pf_o_sin',\n",
    "              'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'dec_o',\n",
    "              'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o',\n",
    "              'like_o', 'prob_o', 'met_o', 'field', 'undergra',\n",
    "              'imprelig', 'imprace', 'from', 'zipcode', 'career', 'sports',\n",
    "              'tvsports', 'exercise', 'dining', 'museums',\n",
    "              'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv',\n",
    "              'theater', 'movies', 'concerts', 'music', 'shopping',\n",
    "              'yoga', 'expnum', 'wave'], axis=1)\n",
    "df = df.dropna(subset=['age'])\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(0)\n",
    "df = pd.get_dummies(df, columns=['field_cd'],\n",
    "                    prefix='field_cd', prefix_sep='=')\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "df.mn_sat = df.mn_sat.fillna(-999)\n",
    "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
    "df.tuition = df.tuition.fillna(-999)\n",
    "#df = pd.get_dummies(df, columns=['race'],\n",
    "#                    prefix='race', prefix_sep='=')\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].fillna(-999)\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(0)\n",
    "df = pd.get_dummies(df, columns=['career_c'],\n",
    "                        prefix='career_c', prefix_sep='=')\n",
    "\n",
    "a = ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, a].sum(axis=1)\n",
    "df.loc[:, a] =\\\n",
    "    (df.loc[:, a].T / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "a = ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, a].sum(axis=1)\n",
    "df.loc[:, a] =\\\n",
    "    (df.loc[:, a].T / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "df = df.drop(['temp_totalsum'], axis=1)\n",
    "\n",
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i), \n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i), \n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    \n",
    "if i != 4:\n",
    "    feat.remove('shar{}_1'.format(i))\n",
    "    \n",
    "df = df.drop(feat, axis=1)\n",
    "\n",
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
    "                                 .drop(['gender'], axis=1)\\\n",
    "                                 .dropna()\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
    "                                   .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1)\\\n",
    "                                   .dropna()\n",
    "        \n",
    "df_female.columns = df_female.columns + '_f'\n",
    "df_female = df_female.drop(['pid_f'], axis=1)\n",
    "df_pair = df_male.join(df_female.set_index('iid_f'), on='pid', how='inner')\n",
    "df_pair = df_pair.drop(['iid', 'pid'], axis=1)\n",
    "X = df_pair.iloc[:, 1:].values\n",
    "y = df_pair.iloc[:, 0].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 85.2 ms, sys: 7.61 ms, total: 92.8 ms\n",
      "Wall time: 91.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 502 ms, sys: 0 ns, total: 502 ms\n",
      "Wall time: 503 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MyDecisionTreeClassifier at 0x7fd402240128>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5358670541769134"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45383275261324035"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field_cd=10.0_f    0.124595\n",
      "attr2_1            0.109317\n",
      "shar1_1_f          0.101267\n",
      "race_f             0.096836\n",
      "attr3_1            0.096658\n",
      "sinc1_1            0.091187\n",
      "shar1_1            0.076101\n",
      "date               0.075152\n",
      "go_out_f           0.068485\n",
      "mn_sat             0.056364\n",
      "dtype: float64\n",
      "int_corr      0.074165\n",
      "income_f      0.030525\n",
      "amb2_1        0.030185\n",
      "exphappy_f    0.024220\n",
      "amb4_1_f      0.023875\n",
      "date          0.022936\n",
      "attr3_1_f     0.022295\n",
      "fun1_1        0.021568\n",
      "shar4_1       0.021214\n",
      "amb3_1_f      0.020402\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = my_clf.feature_importances_ / my_clf.feature_importances_.sum()\n",
    "My_feature = pd.Series(data=data, index=df_pair.columns[1:])\n",
    "\n",
    "data_ = clf.feature_importances_\n",
    "My_feature_ = pd.Series(data=data_, index=df_pair.columns[1:])\n",
    "\n",
    "print(My_feature.sort_values(ascending = False)[:10],'\\n', My_feature_.sort_values(ascending = False)[:10], sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruslanallayarov/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 80, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [i for i in range(1, 10)],\n",
    "    'max_features': ['auto','sqrt','log2'], \n",
    "    'min_impurity_decrease': [i / 1000 for i in range(1, 20)],\n",
    "    \"n_estimators\": [i for i in range(5, 100, 5)],\n",
    "} \n",
    "\n",
    "model = RandomForestClassifier(random_state=123)\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=100, n_jobs=-1,\n",
    "                                   scoring='roc_auc', random_state=123)\n",
    "random_search.fit(X, y)\n",
    "print(random_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
